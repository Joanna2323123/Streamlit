import streamlit as st
import pandas as pd
import zipfile
import matplotlib.pyplot as plt
from io import StringIO
from PyPDF2 import PdfReader
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_experimental.agents import create_pandas_dataframe_agent

# --- ConfiguraÃ§Ã£o da PÃ¡gina ---
st.set_page_config(page_title="Analisador de Dados com Gemini", layout="wide")
st.title("AnÃ¡lise de Dados com Agente Gemini")
st.write(
    "FaÃ§a o upload de arquivos `.zip`, `.csv`, `.xlsx`, `.xls` ou `.pdf`. "
    "O agente usarÃ¡ o modelo Gemini para responder perguntas e gerar visualizaÃ§Ãµes contÃ¡beis, administrativas e fiscais."
)

# --- Chave de API ---
try:
    google_api_key = st.secrets["GOOGLE_API_KEY"]
except (KeyError, FileNotFoundError):
    st.error("Chave de API do Google nÃ£o encontrada. Configure-a nos 'Secrets' do seu aplicativo Streamlit Cloud.")
    st.stop()

# --- Upload ---
uploaded_files = st.file_uploader(
    "Envie um ou mais arquivos (.zip, .csv, .xlsx, .xls ou .pdf)",
    type=["zip", "csv", "xlsx", "xls", "pdf"],
    accept_multiple_files=True
)

if 'df' not in st.session_state:
    st.session_state.df = None
if 'selected_file' not in st.session_state:
    st.session_state.selected_file = ""

# --- Leitura completa de dados ---
if uploaded_files:
    try:
        pdf_files = [f for f in uploaded_files if f.name.endswith(".pdf")]
        zip_files = [f for f in uploaded_files if f.name.endswith(".zip")]
        csv_files = [f for f in uploaded_files if f.name.endswith(".csv")]
        excel_files = [f for f in uploaded_files if f.name.endswith((".xls", ".xlsx"))]

        # ZIP
        if zip_files:
            uploaded_file = zip_files[0]
            with zipfile.ZipFile(uploaded_file, "r") as zip_ref:
                csv_inside = [f for f in zip_ref.namelist() if f.endswith('.csv')]
                if csv_inside:
                    selected_csv = st.selectbox("Selecione um CSV dentro do ZIP:", csv_inside)
                    if selected_csv:
                        with zip_ref.open(selected_csv) as f:
                            stringio = StringIO(f.read().decode('utf-8'))
                            st.session_state.df = pd.read_csv(stringio, low_memory=False, encoding_errors='ignore')
                            st.session_state.selected_file = selected_csv

        # CSV individual
        elif csv_files:
            uploaded_file = csv_files[0]
            st.session_state.selected_file = uploaded_file.name
            stringio = StringIO(uploaded_file.getvalue().decode('utf-8', errors='ignore'))
            st.session_state.df = pd.read_csv(stringio, low_memory=False, encoding_errors='ignore')

        # Excel individual (.xls / .xlsx)
        elif excel_files:
            uploaded_file = excel_files[0]
            st.session_state.selected_file = uploaded_file.name
            st.session_state.df = pd.read_excel(uploaded_file, engine="openpyxl")

        # PDFs mÃºltiplos
        elif pdf_files:
            st.info("ðŸ“‚ PDFs carregados â€” perguntas textuais podem ser feitas ao modelo Gemini (sem dataframe).")
            st.session_state.df = None

    except Exception as e:
        st.error(f"Erro ao processar os arquivos: {e}")
        st.session_state.df = None

# --- InteraÃ§Ã£o com o Agente Gemini ---
if st.session_state.df is not None:
    df = st.session_state.df
    st.success(f"Arquivo '{st.session_state.selected_file}' carregado com sucesso.")
    st.dataframe(df, use_container_width=True, height=700)
    st.write(f"**Total de linhas carregadas:** {len(df):,}")

    user_question = st.text_input(
        "FaÃ§a uma pergunta sobre os dados:",
        placeholder="Exemplo: Classifique os lanÃ§amentos como Vale, EmprÃ©stimo ou Adiantamento em tabela."
    )

    if user_question:
        with st.spinner("O Agente estÃ¡ analisando seus dados..."):
            llm = ChatGoogleGenerativeAI(
                model="gemini-2.5-flash",
                temperature=0,
                google_api_key=google_api_key
            )

            # Se o usuÃ¡rio pedir classificaÃ§Ã£o -> tratamos localmente
            if "classifique" in user_question.lower() or "classificaÃ§Ã£o" in user_question.lower():
                if "DescriÃ§Ã£o" in df.columns or "descriÃ§Ã£o" in df.columns:
                    desc_col = "DescriÃ§Ã£o" if "DescriÃ§Ã£o" in df.columns else "descriÃ§Ã£o"
                    classificacoes = []

                    # LÃ³gica simples: classificar por palavra-chave
                    for texto in df[desc_col].astype(str):
                        texto_lower = texto.lower()
                        if "vale" in texto_lower:
                            classificacoes.append("Vale / Adiantamento de pagamento")
                        elif "emprest" in texto_lower:
                            classificacoes.append("EmprÃ©stimo / Reembolso")
                        elif "adiant" in texto_lower:
                            classificacoes.append("Adiantamento")
                        elif "salÃ¡rio" in texto_lower or "pagamento" in texto_lower:
                            classificacoes.append("Despesa / Pagamento")
                        elif "contabilidade" in texto_lower or "taxa" in texto_lower:
                            classificacoes.append("ServiÃ§o / Custo Operacional")
                        else:
                            classificacoes.append("Outros")

                    df["ClassificaÃ§Ã£o AutomÃ¡tica"] = classificacoes
                    st.success("âœ… ClassificaÃ§Ã£o automÃ¡tica concluÃ­da.")
                    st.dataframe(df[[desc_col, "ClassificaÃ§Ã£o AutomÃ¡tica"]], use_container_width=True)
                else:
                    st.warning("NÃ£o foi possÃ­vel encontrar uma coluna de descriÃ§Ã£o para classificar.")

            else:
                # Pergunta analÃ­tica normal via Gemini
                try:
                    AGENT_PREFIX = """
                    VocÃª Ã© um Cientista ContÃ¡bil e Administrador Financeiro. 
                    Analise planilhas completas, sem limitaÃ§Ã£o de linhas, e gere respostas analÃ­ticas, contÃ¡beis e administrativas.
                    """
                    agent = create_pandas_dataframe_agent(
                        llm,
                        df,
                        prefix=AGENT_PREFIX,
                        verbose=False,
                        agent_type="openai-tools",
                        handle_parsing_errors=True,
                        allow_dangerous_code=True,
                    )

                    plt.close('all')
                    response = agent.invoke({"input": user_question})
                    output_text = response.get("output", "NÃ£o foi possÃ­vel gerar uma resposta.")

                    st.success("ðŸ“Š Resposta do Agente:")
                    st.write(output_text)

                    fig = plt.gcf()
                    if len(fig.get_axes()) > 0:
                        st.write("---")
                        st.subheader("ðŸ“ˆ VisualizaÃ§Ã£o Gerada")
                        st.pyplot(fig)
                except Exception as e:
                    st.error(f"Ocorreu um erro durante a execuÃ§Ã£o do agente: {e}")

elif uploaded_files and any(f.name.endswith(".pdf") for f in uploaded_files):
    user_question = st.text_input(
        "Pergunte algo sobre o texto dos PDFs:",
        placeholder="Exemplo: Resuma o conteÃºdo dos documentos fiscais."
    )
    if user_question:
        with st.spinner("O Agente estÃ¡ analisando o PDF..."):
            try:
                llm = ChatGoogleGenerativeAI(
                    model="gemini-2.5-flash",
                    temperature=0,
                    google_api_key=google_api_key
                )
                full_text = ""
                for pdf in [f for f in uploaded_files if f.name.endswith(".pdf")]:
                    reader = PdfReader(pdf)
                    for page in reader.pages:
                        full_text += page.extract_text() or ""
                response = llm.invoke(f"Responda com base neste texto:\n{full_text}\n\nPergunta: {user_question}")
                st.success("ðŸ“˜ Resposta do Agente:")
                st.write(response.content)
            except Exception as e:
                st.error(f"Erro ao processar o PDF: {e}")

else:
    st.info("Aguardando o upload de um arquivo (.zip, .csv, .xlsx, .xls ou .pdf) para iniciar a anÃ¡lise.")

